{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Predicting Credit defaulters using Deep Learning\n\nIn this blog, we will be performing binary classification by predicting a credit defaulter using age, sex, marital status, education, history of past payment, amount of bill statement and past payment. This kind of model is useful for banks and credit card companies to determine if a person is likely to default on a bill/loan. We will be using feed forward neural networks here. The dataset for this problem is taken from: https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset\n\nWe will create a model with the following steps:\n1. Download and explore the dataset\n2. Prepare the dataset for training\n3. Create a linear regression model\n4. Train the model to fit the data\n5. Make predictions using the trained model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!conda install numpy pytorch torchvision cpuonly -c pytorch -y\n#!pip install matplotlib --upgrade --quiet\n!pip install jovian --upgrade --quiet","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport jovian\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"project_name='default-credit-card' # will be used by jovian.commit","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Download and explore the data\n\nThis dataset is available in Kaggle so we just add it using 'Add Data' option."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_FILENAME = \"../input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\"","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> To load this CSV type dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe = pd.read_csv(DATA_FILENAME)\ndataframe.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n0   1    20000.0    2          2         1   24      2      2     -1     -1   \n1   2   120000.0    2          2         2   26     -1      2      0      0   \n2   3    90000.0    2          2         2   34      0      0      0      0   \n3   4    50000.0    2          2         1   37      0      0      0      0   \n4   5    50000.0    1          2         1   57     -1      0     -1      0   \n\n   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n\n   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n0       0.0       0.0       0.0                           1  \n1    1000.0       0.0    2000.0                           1  \n2    1000.0    1000.0    5000.0                           0  \n3    1100.0    1069.0    1000.0                           0  \n4    9000.0     689.0     679.0                           0  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LIMIT_BAL</th>\n      <th>SEX</th>\n      <th>EDUCATION</th>\n      <th>MARRIAGE</th>\n      <th>AGE</th>\n      <th>PAY_0</th>\n      <th>PAY_2</th>\n      <th>PAY_3</th>\n      <th>PAY_4</th>\n      <th>...</th>\n      <th>BILL_AMT4</th>\n      <th>BILL_AMT5</th>\n      <th>BILL_AMT6</th>\n      <th>PAY_AMT1</th>\n      <th>PAY_AMT2</th>\n      <th>PAY_AMT3</th>\n      <th>PAY_AMT4</th>\n      <th>PAY_AMT5</th>\n      <th>PAY_AMT6</th>\n      <th>default.payment.next.month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>24</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>689.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>120000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>26</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3272.0</td>\n      <td>3455.0</td>\n      <td>3261.0</td>\n      <td>0.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>0.0</td>\n      <td>2000.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>90000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>14331.0</td>\n      <td>14948.0</td>\n      <td>15549.0</td>\n      <td>1518.0</td>\n      <td>1500.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>1000.0</td>\n      <td>5000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>50000.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>28314.0</td>\n      <td>28959.0</td>\n      <td>29547.0</td>\n      <td>2000.0</td>\n      <td>2019.0</td>\n      <td>1200.0</td>\n      <td>1100.0</td>\n      <td>1069.0</td>\n      <td>1000.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50000.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>57</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>20940.0</td>\n      <td>19146.0</td>\n      <td>19131.0</td>\n      <td>2000.0</td>\n      <td>36681.0</td>\n      <td>10000.0</td>\n      <td>9000.0</td>\n      <td>689.0</td>\n      <td>679.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Attribute Information:**\n\nThis research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n\nX1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.'LIMIT_BAL'\n\nX2: Gender (1 = male; 2 = female). 'SEX'\n\nX3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). 'EDUCATION'\n\nX4: Marital status (1 = married; 2 = single; 3 = others). 'MARRIAGE'\n\nX5: Age (year).\n\nX6 - X11: History of past payment.\n\nThe past monthly payment records (from April to September, 2005) as follows:\n\nX6 = the repayment status in September, 2005;\n\nX7 = the repayment status in August, 2005; X8 = the repayment status in July, 2005; X9 = the repayment status in June, 2005; X10 = the repayment status in May, 2005;\n\nX11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n\nX12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n\nX18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_cols=['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above are column titles for the input variables. "},{"metadata":{"trusted":true},"cell_type":"code","source":"output_cols='default.payment.next.month'\n# This is the response/target variable we are trying to predict","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols=['SEX', 'EDUCATION', 'MARRIAGE',  'PAY_0',\n       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\ncont_cols=['LIMIT_BAL','BILL_AMT1', 'BILL_AMT2','AGE',\n       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.title(\"Distribution of default Payment\")\nsns.countplot(x='default.payment.next.month',data=dataframe,palette=['magenta','orange']);","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"As one would expect majority of the customers are non-defaulters or pay their debts on time."},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\na4_dims = (14, 6)\nfig, ax = pyplot.subplots(figsize=a4_dims)\nsns.countplot(dataframe['AGE'],ax=ax)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7ff0cd3b2310>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"Looking at the distribution of age, a lot of them are in 27-30 range."},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"},"metadata":{}},{"output_type":"stream","text":"[jovian] Attempting to save notebook..\u001b[0m\n[jovian] Detected Kaggle notebook...\u001b[0m\n[jovian] Please enter your API key ( from https://jovian.ml/ ):\u001b[0m\nAPI KEY: ········\n[jovian] Uploading notebook to https://jovian.ml/mukundan-sankar14/default-credit-card\u001b[0m\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    require([\"base/js/namespace\"],function(Jupyter) {\n        var nbJson = JSON.stringify(Jupyter.notebook.toJSON());\n\n        console.log(\"[jovian] Extracted notebook JSON:\");\n        console.log(nbJson);\n\n        function jvnLog (data) {\n          console.log(\"Result from jovian.commit:\");\n          if (data.content.text) {\n              var result = JSON.parse(data.content.text.trim());\n              var msg = result['msg'];\n              var err = result['err'];\n              if (msg) {\n                  element.text(\"Committed successfully: \" + msg)\n              } else {\n                  alert(\"Notebook commit failed. Error: \" + (err || \"Unknown\"))\n              }\n          }\n          \n        };\n        \n        var pythonCode = `\nfrom contextlib import redirect_stdout, redirect_stderr\nfrom io import StringIO\nimport json\n \nwith open(\"default-credit-card.ipynb\", 'w') as f:\n    f.write(r\"\"\"${nbJson}\"\"\")\n\njvn_update = StringIO()\njvn_update_err = StringIO()\nwith redirect_stdout(jvn_update), redirect_stderr(jvn_update_err):\n    from jovian import commit\n\njvn_f_out = StringIO()\njvn_f_err = StringIO()\nwith redirect_stdout(jvn_f_out), redirect_stderr(jvn_f_err):\n    jvn_msg = jovian.commit(message=None, files=[], outputs=[], environment=None, privacy='auto', filename='default-credit-card.ipynb', project='default-credit-card', new_project=None)\n\nprint(json.dumps({'msg': jvn_msg, 'err': jvn_f_err.getvalue(), 'update': jvn_update.getvalue()}))\n        `;\n\n        console.log(\"Invoking jovian.commit\")\n        // console.log(pythonCode)\n\n        Jupyter.notebook.kernel.execute(pythonCode, { iopub: { output: jvnLog }});\n    });"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Prepare the dataset for training\n\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe\n    dataframe1 = dataframe.copy(deep=True)\n    # Convert non-numeric categorical columns to numbers\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n    # Extract input & outupts as numpy arrays\n    inputs_array = dataframe1[input_cols].to_numpy()\n    targets_array = dataframe1[output_cols].to_numpy()\n    return inputs_array, targets_array","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs_array, targets_array = dataframe_to_arrays(dataframe)\ninputs_array, targets_array","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"(array([[2.0000e+04, 1.0000e+00, 2.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [1.2000e+05, 1.0000e+00, 2.0000e+00, ..., 1.0000e+03, 0.0000e+00,\n         2.0000e+03],\n        [9.0000e+04, 1.0000e+00, 2.0000e+00, ..., 1.0000e+03, 1.0000e+03,\n         5.0000e+03],\n        ...,\n        [3.0000e+04, 0.0000e+00, 2.0000e+00, ..., 4.2000e+03, 2.0000e+03,\n         3.1000e+03],\n        [8.0000e+04, 0.0000e+00, 3.0000e+00, ..., 1.9260e+03, 5.2964e+04,\n         1.8040e+03],\n        [5.0000e+04, 0.0000e+00, 2.0000e+00, ..., 1.0000e+03, 1.0000e+03,\n         1.0000e+03]]),\n array([1, 1, 0, ..., 1, 1, 1]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ninputs = torch.from_numpy(np.array(inputs_array,dtype=np.float32))\ntargets = torch.from_numpy(np.array(targets_array,dtype=np.float32))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.dtype, targets.dtype","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(torch.float32, torch.float32)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = TensorDataset(inputs, targets)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_percent = 0.2 \nnum_rows=len(dataframe)\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\ntrain_ds, val_ds = random_split(dataset,[train_size,val_size]) # Use the random_split function to split dataset into 2 parts of the desired length","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we can create data loaders for training & validation.\n\n**Picking a batch size for the data loader.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = len(input_cols)\nnum_classes=2","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)\n#or input_s,labels in train_loader:\nfor xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break    ","execution_count":20,"outputs":[{"output_type":"stream","text":"inputs: tensor([[ 1.0000e+05,  1.0000e+00,  2.0000e+00,  2.0000e+00,  2.4000e+01,\n          4.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  1.7765e+05,  9.4299e+04,  9.6389e+04,  9.7571e+04,\n          8.6202e+04,  9.2282e+04,  7.9000e+03,  4.5000e+03,  3.8000e+03,\n          3.5000e+03,  7.5000e+03,  3.5000e+03],\n        [ 2.4000e+05,  1.0000e+00,  2.0000e+00,  1.0000e+00,  3.8000e+01,\n          2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  2.3199e+05,  2.0271e+05,  1.9971e+05,  2.0377e+05,\n          2.0802e+05,  2.2011e+05,  1.0028e+04,  7.7110e+03,  7.7670e+03,\n          8.0150e+03,  1.5829e+04,  9.0000e+03],\n        [ 2.0000e+05,  1.0000e+00,  2.0000e+00,  2.0000e+00,  3.5000e+01,\n          2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  7.2450e+04,  5.2795e+04,  4.1861e+04,  3.4531e+04,\n          1.7940e+03, -3.4500e+02,  5.5560e+03,  1.0000e+03,  2.0000e+03,\n          1.0000e+03,  0.0000e+00,  0.0000e+00],\n        [ 4.0000e+05,  0.0000e+00,  1.0000e+00,  1.0000e+00,  4.4000e+01,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  4.4820e+03, -1.0000e+01,  1.9030e+03,  8.5000e+02,\n          8.0800e+02,  7.7500e+02,  0.0000e+00,  1.9130e+03,  8.5000e+02,\n          8.0800e+02,  7.7500e+02,  3.8000e+02],\n        [ 5.0000e+05,  0.0000e+00,  2.0000e+00,  1.0000e+00,  3.3000e+01,\n          2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  5.3220e+03,  5.9200e+03,  6.0610e+03,  7.2890e+03,\n          8.3130e+03,  6.4900e+03,  1.1250e+03,  1.2800e+03,  1.7910e+03,\n          1.5280e+03,  1.5120e+03,  1.3700e+03],\n        [ 2.1000e+05,  1.0000e+00,  1.0000e+00,  1.0000e+00,  3.4000e+01,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,\n          0.0000e+00,  2.5010e+03,  6.3900e+02,  6.9900e+02,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  6.3900e+02,  6.9900e+02,  0.0000e+00,\n          0.0000e+00,  0.0000e+00,  0.0000e+00],\n        [ 2.7000e+05,  1.0000e+00,  1.0000e+00,  2.0000e+00,  2.8000e+01,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  2.0000e+00,\n          1.0000e+00,  1.5167e+04,  8.4100e+02,  9.8420e+03,  7.9310e+03,\n          3.4120e+03,  1.0350e+03,  8.4500e+02,  9.8960e+03,  7.9770e+03,\n          1.7000e+01,  1.0400e+03,  1.8480e+03],\n        [ 1.8000e+05,  1.0000e+00,  2.0000e+00,  2.0000e+00,  2.4000e+01,\n          3.0000e+00,  4.0000e+00,  4.0000e+00,  4.0000e+00,  3.0000e+00,\n          3.0000e+00,  1.0858e+05,  1.0540e+05,  1.1207e+05,  1.1134e+05,\n          9.8404e+04,  1.0246e+05,  0.0000e+00,  8.5640e+03,  4.0000e+03,\n          0.0000e+00,  7.4140e+03,  0.0000e+00],\n        [ 5.0000e+04,  0.0000e+00,  1.0000e+00,  2.0000e+00,  3.5000e+01,\n          4.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  5.0481e+04,  4.8264e+04,  1.9142e+04,  1.8188e+04,\n          1.8397e+04,  1.8161e+04,  3.1830e+03,  1.5650e+03,  7.2400e+03,\n          7.9500e+02,  1.0000e+03,  6.7300e+02],\n        [ 1.9000e+05,  1.0000e+00,  1.0000e+00,  2.0000e+00,  2.6000e+01,\n          2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  1.7452e+05,  1.7912e+05,  1.8268e+05,  1.5475e+05,\n          9.0540e+04,  9.2248e+04,  9.0000e+03,  8.3820e+03,  1.0221e+04,\n          1.0000e+04,  3.0000e+03,  1.0490e+04],\n        [ 3.0000e+04,  0.0000e+00,  2.0000e+00,  2.0000e+00,  2.6000e+01,\n          2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          3.0000e+00,  2.7889e+04,  2.6990e+04,  2.4706e+04,  2.5022e+04,\n          2.6405e+04,  2.5861e+04,  2.8750e+03,  4.9000e+03,  2.0000e+03,\n          2.1000e+03,  0.0000e+00,  2.5000e+03],\n        [ 4.9000e+05,  1.0000e+00,  1.0000e+00,  1.0000e+00,  3.7000e+01,\n          3.0000e+00,  4.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  1.8961e+04,  1.1232e+04,  1.9173e+04,  2.0400e+04,\n          2.7979e+04,  2.7622e+04,  0.0000e+00,  9.1730e+03,  5.4000e+03,\n          7.9790e+03,  7.6220e+03,  0.0000e+00],\n        [ 3.0000e+04,  1.0000e+00,  2.0000e+00,  1.0000e+00,  4.3000e+01,\n          4.0000e+00,  4.0000e+00,  4.0000e+00,  4.0000e+00,  3.0000e+00,\n          2.0000e+00,  2.8703e+04,  2.6622e+04,  2.4022e+04,  2.4368e+04,\n          2.0859e+04,  1.9633e+04,  1.3000e+03,  2.0000e+00,  1.6080e+03,\n          0.0000e+00,  9.0000e+02,  8.0000e+02],\n        [ 1.3000e+05,  1.0000e+00,  2.0000e+00,  2.0000e+00,  3.2000e+01,\n          2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  7.4690e+03,  8.4720e+03,  9.1430e+03,  9.7410e+03,\n          9.7130e+03,  9.4580e+03,  1.1380e+03,  1.1730e+03,  1.1380e+03,\n          4.7700e+02,  4.0000e+02,  6.0000e+02],\n        [ 5.0000e+04,  1.0000e+00,  2.0000e+00,  1.0000e+00,  3.8000e+01,\n          2.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.2260e+03,  1.2260e+03,  1.2260e+03,  1.2260e+03,\n          1.7650e+03,  1.0660e+03,  1.2260e+03,  1.2260e+03,  1.2260e+03,\n          1.7650e+03,  1.0660e+03,  1.7000e+02],\n        [ 6.0000e+04,  1.0000e+00,  1.0000e+00,  2.0000e+00,  2.6000e+01,\n          2.0000e+00,  2.0000e+00,  4.0000e+00,  2.0000e+00,  2.0000e+00,\n          2.0000e+00,  2.2921e+04,  2.3044e+04,  1.7660e+04,  1.3104e+04,\n          8.7220e+03,  1.7976e+04,  5.0000e+03,  0.0000e+00,  0.0000e+00,\n          1.7400e+02,  1.3810e+04,  0.0000e+00]])\ntargets: tensor([0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Let's save our work by committing to Jovian."},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"},"metadata":{}},{"output_type":"stream","text":"[jovian] Attempting to save notebook..\u001b[0m\n[jovian] Detected Kaggle notebook...\u001b[0m\n[jovian] Uploading notebook to https://jovian.ml/mukundan-sankar14/default-credit-card\u001b[0m\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    require([\"base/js/namespace\"],function(Jupyter) {\n        var nbJson = JSON.stringify(Jupyter.notebook.toJSON());\n\n        console.log(\"[jovian] Extracted notebook JSON:\");\n        console.log(nbJson);\n\n        function jvnLog (data) {\n          console.log(\"Result from jovian.commit:\");\n          if (data.content.text) {\n              var result = JSON.parse(data.content.text.trim());\n              var msg = result['msg'];\n              var err = result['err'];\n              if (msg) {\n                  element.text(\"Committed successfully: \" + msg)\n              } else {\n                  alert(\"Notebook commit failed. Error: \" + (err || \"Unknown\"))\n              }\n          }\n          \n        };\n        \n        var pythonCode = `\nfrom contextlib import redirect_stdout, redirect_stderr\nfrom io import StringIO\nimport json\n \nwith open(\"default-credit-card.ipynb\", 'w') as f:\n    f.write(r\"\"\"${nbJson}\"\"\")\n\njvn_update = StringIO()\njvn_update_err = StringIO()\nwith redirect_stdout(jvn_update), redirect_stderr(jvn_update_err):\n    from jovian import commit\n\njvn_f_out = StringIO()\njvn_f_err = StringIO()\nwith redirect_stdout(jvn_f_out), redirect_stderr(jvn_f_err):\n    jvn_msg = jovian.commit(message=None, files=[], outputs=[], environment=None, privacy='auto', filename='default-credit-card.ipynb', project='default-credit-card', new_project=None)\n\nprint(json.dumps({'msg': jvn_msg, 'err': jvn_f_err.getvalue(), 'update': jvn_update.getvalue()}))\n        `;\n\n        console.log(\"Invoking jovian.commit\")\n        // console.log(pythonCode)\n\n        Jupyter.notebook.kernel.execute(pythonCode, { iopub: { output: jvnLog }});\n    });"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4: Train the model to fit the data\n\nTo train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."},{"metadata":{},"cell_type":"markdown","source":"## Using Sigmoid function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CreditModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #hidden layer 1\n        self.linear1 = nn.Linear(input_size, 16)\n        #hidden layer 2\n        self.linear2 = nn.Linear(16,8)\n        #hidden layer 3\n        self.linear3 = nn.Linear(8,4)\n        # output layer\n        self.linear_out = nn.Linear(4,num_classes)\n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout(p=0.5)\n        self.batchnorm1 = nn.BatchNorm1d(16)\n        self.batchnorm2 = nn.BatchNorm1d(8)\n        self.batchnorm3 = nn.BatchNorm1d(4)\n        \n    def forward(self, inputs):\n        x = self.sigmoid(self.linear1(inputs))\n        x = self.batchnorm1(x)\n        x = self.sigmoid(self.linear2(x))\n        x = self.batchnorm2(x)\n        x = self.sigmoid(self.linear3(x))\n        x = self.batchnorm3(x)\n        x = self.dropout(x)\n        x = self.linear_out(x)\n        \n        return x\n\n    \n    def training_step(self, batch):\n        images, labels = batch \n        labels=labels.type(torch.long)\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        labels=labels.type(torch.long)\n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel = CreditModel()\nmodel","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"CreditModel(\n  (linear1): Linear(in_features=23, out_features=16, bias=True)\n  (linear2): Linear(in_features=16, out_features=8, bias=True)\n  (linear3): Linear(in_features=8, out_features=4, bias=True)\n  (linear_out): Linear(in_features=4, out_features=2, bias=True)\n  (sigmoid): Sigmoid()\n  (dropout): Dropout(p=0.5, inplace=False)\n  (batchnorm1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (batchnorm3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CreditModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #hidden layer 1\n        self.linear1 = nn.Linear(input_size, 16)\n        #hidden layer 2\n        self.linear2 = nn.Linear(16,8)\n        #hidden layer 3\n        self.linear3 = nn.Linear(8,4)\n        # output layer\n        self.linear_out = nn.Linear(4,num_classes)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, inputs):\n        x = self.sigmoid(self.linear1(inputs))\n        x = self.sigmoid(self.linear2(x))\n        x = self.sigmoid(self.linear3(x))\n        x = self.linear_out(x)\n        \n        return x\n\n    \n    def training_step(self, batch):\n        images, labels = batch \n        labels=labels.type(torch.long)\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        labels=labels.type(torch.long)\n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch_sigmoid [{}], val_loss_sigmoid: {:.4f}, val_acc_sigmoid: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel = CreditModel()\nmodel","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"CreditModel(\n  (linear1): Linear(in_features=23, out_features=16, bias=True)\n  (linear2): Linear(in_features=16, out_features=8, bias=True)\n  (linear3): Linear(in_features=8, out_features=4, bias=True)\n  (linear_out): Linear(in_features=4, out_features=2, bias=True)\n  (sigmoid): Sigmoid()\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            images, labels = batch\n            out = model(images)\n            labels=labels.type(torch.long)\n            #             loss = model.training_step(batch)\n            loss = F.cross_entropy(out, labels)   #y_batch.unsqueeze(1)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = evaluate(model,val_loader) # Use the the evaluate function\nprint(result)","execution_count":26,"outputs":[{"output_type":"stream","text":"{'val_loss': 0.7018009424209595, 'val_acc': 0.22233332693576813}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nlr = 1e-3\nhistory = fit(epochs, lr, model, train_loader, val_loader)","execution_count":27,"outputs":[{"output_type":"stream","text":"Epoch_sigmoid [0], val_loss_sigmoid: 0.5462, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [1], val_loss_sigmoid: 0.5317, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [2], val_loss_sigmoid: 0.5301, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [3], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [4], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [5], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [6], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [7], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [8], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\nEpoch_sigmoid [9], val_loss_sigmoid: 0.5298, val_acc_sigmoid: 0.7777\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Using Softmax function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CreditModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #hidden layer 1\n        self.linear1 = nn.Linear(input_size, 256)\n        #hidden layer 2\n        self.linear2 = nn.Linear(256,128)\n        #hidden layer 3\n        self.linear3 = nn.Linear(128,32)\n        #hidden layer 4\n        self.linear4 = nn.Linear(32,8)\n        \n        self.softmax = nn.Softmax()\n        self.dropout = nn.Dropout(p=0.5)\n        #.batchnorm1 = nn.BatchNorm1d(256)\n        #self.batchnorm2 = nn.BatchNorm1d(128)\n        #self.batchnorm3 = nn.BatchNorm1d(32)\n        #self.batchnorm4 = nn.BatchNorm1d(8)\n        # output layer\n        self.linear_out = nn.Linear(8,num_classes)\n        \n    def forward(self, inputs):\n        x = self.softmax(self.linear1(inputs))\n        #x = self.batchnorm1(x)\n        x = self.softmax(self.linear2(x))\n        #x = self.batchnorm2(x)\n        x = self.softmax(self.linear3(x))\n        #x = self.batchnorm3(x)\n        x = self.softmax(self.linear4(x))\n        #x = self.batchnorm4(x)\n        \n        x = self.dropout(x)\n        x = self.linear_out(x)\n        \n        return x\n\n    \n    def training_step(self, batch):\n        images, labels = batch \n        labels=labels.type(torch.long)\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        labels=labels.type(torch.long)\n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch_softmax [{}], val_loss_softmax: {:.4f}, val_acc_softmax: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel_softmax = CreditModel()\nmodel_softmax","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"CreditModel(\n  (linear1): Linear(in_features=23, out_features=256, bias=True)\n  (linear2): Linear(in_features=256, out_features=128, bias=True)\n  (linear3): Linear(in_features=128, out_features=32, bias=True)\n  (linear4): Linear(in_features=32, out_features=8, bias=True)\n  (softmax): Softmax(dim=None)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (linear_out): Linear(in_features=8, out_features=2, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            images, labels = batch\n            out = model(images)\n            labels=labels.type(torch.long)\n            #             loss = model.training_step(batch)\n            loss = F.cross_entropy(out, labels)   #y_batch.unsqueeze(1)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = evaluate(model_softmax,val_loader) # Use the the evaluate function\nprint(result)\nepochs = 10\nlr = 1e-3\nhistory = fit(epochs, lr, model_softmax, train_loader, val_loader)","execution_count":30,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","name":"stderr"},{"output_type":"stream","text":"{'val_loss': 0.6754872798919678, 'val_acc': 0.6493333578109741}\nEpoch_softmax [0], val_loss_softmax: 0.5633, val_acc_softmax: 0.7777\nEpoch_softmax [1], val_loss_softmax: 0.5393, val_acc_softmax: 0.7777\nEpoch_softmax [2], val_loss_softmax: 0.5337, val_acc_softmax: 0.7777\nEpoch_softmax [3], val_loss_softmax: 0.5313, val_acc_softmax: 0.7777\nEpoch_softmax [4], val_loss_softmax: 0.5304, val_acc_softmax: 0.7777\nEpoch_softmax [5], val_loss_softmax: 0.5302, val_acc_softmax: 0.7777\nEpoch_softmax [6], val_loss_softmax: 0.5304, val_acc_softmax: 0.7777\nEpoch_softmax [7], val_loss_softmax: 0.5304, val_acc_softmax: 0.7777\nEpoch_softmax [8], val_loss_softmax: 0.5298, val_acc_softmax: 0.7777\nEpoch_softmax [9], val_loss_softmax: 0.5302, val_acc_softmax: 0.7777\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"val_loss = 0.5014 #with 10 epochs and 1e-3 learning rate for ReLU sounds better than sigmoid. \nHowever, ReLU took more time than sigmoid so we will use Sigmoid since the difference in accuracy is only slight."},{"metadata":{},"cell_type":"markdown","source":"Let's log the final validation loss to Jovian and commit the notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss=0.5298\njovian.log_metrics(val_loss=val_loss)","execution_count":35,"outputs":[{"output_type":"stream","text":"[jovian] Metrics logged.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"},"metadata":{}},{"output_type":"stream","text":"[jovian] Attempting to save notebook..\u001b[0m\n[jovian] Detected Kaggle notebook...\u001b[0m\n[jovian] Uploading notebook to https://jovian.ml/mukundan-sankar14/default-credit-card\u001b[0m\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    require([\"base/js/namespace\"],function(Jupyter) {\n        var nbJson = JSON.stringify(Jupyter.notebook.toJSON());\n\n        console.log(\"[jovian] Extracted notebook JSON:\");\n        console.log(nbJson);\n\n        function jvnLog (data) {\n          console.log(\"Result from jovian.commit:\");\n          if (data.content.text) {\n              var result = JSON.parse(data.content.text.trim());\n              var msg = result['msg'];\n              var err = result['err'];\n              if (msg) {\n                  element.text(\"Committed successfully: \" + msg)\n              } else {\n                  alert(\"Notebook commit failed. Error: \" + (err || \"Unknown\"))\n              }\n          }\n          \n        };\n        \n        var pythonCode = `\nfrom contextlib import redirect_stdout, redirect_stderr\nfrom io import StringIO\nimport json\n \nwith open(\"default-credit-card.ipynb\", 'w') as f:\n    f.write(r\"\"\"${nbJson}\"\"\")\n\njvn_update = StringIO()\njvn_update_err = StringIO()\nwith redirect_stdout(jvn_update), redirect_stderr(jvn_update_err):\n    from jovian import commit\n\njvn_f_out = StringIO()\njvn_f_err = StringIO()\nwith redirect_stdout(jvn_f_out), redirect_stderr(jvn_f_err):\n    jvn_msg = jovian.commit(message=None, files=[], outputs=[], environment=None, privacy='auto', filename='default-credit-card.ipynb', project='default-credit-card', new_project=None)\n\nprint(json.dumps({'msg': jvn_msg, 'err': jvn_f_err.getvalue(), 'update': jvn_update.getvalue()}))\n        `;\n\n        console.log(\"Invoking jovian.commit\")\n        // console.log(pythonCode)\n\n        Jupyter.notebook.kernel.execute(pythonCode, { iopub: { output: jvnLog }});\n    });"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."},{"metadata":{},"cell_type":"markdown","source":"## Step 5: Make predictions using the trained model\n\n**Q: Complete the following function definition to make predictions on a single input**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)             \n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[0]\npredict_single(input, target, model)","execution_count":40,"outputs":[{"output_type":"stream","text":"Input: tensor([1.0000e+05, 0.0000e+00, 2.0000e+00, 1.0000e+00, 5.0000e+01, 2.0000e+00,\n        2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 2.0000e+00, 9.5549e+04,\n        9.8909e+04, 8.1181e+04, 4.8194e+04, 4.0692e+04, 1.8110e+04, 5.0250e+03,\n        2.9390e+03, 1.8263e+04, 1.5761e+04, 4.1800e+02, 5.8300e+02])\nTarget: tensor(0.)\nPrediction: tensor([ 0.6797, -0.5825])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[10]\npredict_single(input, target, model)","execution_count":41,"outputs":[{"output_type":"stream","text":"Input: tensor([7.0000e+04, 1.0000e+00, 2.0000e+00, 3.0000e+00, 4.2000e+01, 2.0000e+00,\n        2.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00, 1.0000e+00, 6.9486e+04,\n        6.8650e+04, 6.5458e+04, 1.9087e+04, 1.0220e+04, 1.1913e+04, 3.0000e+03,\n        1.6040e+03, 1.0000e+03, 1.0220e+04, 1.1913e+04, 1.0000e+04])\nTarget: tensor(0.)\nPrediction: tensor([ 0.6824, -0.5808])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input, target = val_ds[23]\npredict_single(input, target, model)","execution_count":42,"outputs":[{"output_type":"stream","text":"Input: tensor([ 4.2000e+05,  1.0000e+00,  2.0000e+00,  2.0000e+00,  2.9000e+01,\n         2.0000e+00,  2.0000e+00,  2.0000e+00,  2.0000e+00,  1.0000e+00,\n         2.0000e+00,  8.2235e+04,  6.7757e+04,  5.3524e+04, -8.3180e+03,\n         9.6795e+04,  8.1523e+04,  3.0000e+03,  3.0000e+03,  1.8200e+02,\n         1.2300e+05,  2.7400e+03,  2.2000e+03])\nTarget: tensor(0.)\nPrediction: tensor([ 0.6838, -0.5783])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, environment=None)","execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"},"metadata":{}},{"output_type":"stream","text":"[jovian] Attempting to save notebook..\u001b[0m\n[jovian] Detected Kaggle notebook...\u001b[0m\n[jovian] Uploading notebook to https://jovian.ml/mukundan-sankar14/default-credit-card\u001b[0m\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    require([\"base/js/namespace\"],function(Jupyter) {\n        var nbJson = JSON.stringify(Jupyter.notebook.toJSON());\n\n        console.log(\"[jovian] Extracted notebook JSON:\");\n        console.log(nbJson);\n\n        function jvnLog (data) {\n          console.log(\"Result from jovian.commit:\");\n          if (data.content.text) {\n              var result = JSON.parse(data.content.text.trim());\n              var msg = result['msg'];\n              var err = result['err'];\n              if (msg) {\n                  element.text(\"Committed successfully: \" + msg)\n              } else {\n                  alert(\"Notebook commit failed. Error: \" + (err || \"Unknown\"))\n              }\n          }\n          \n        };\n        \n        var pythonCode = `\nfrom contextlib import redirect_stdout, redirect_stderr\nfrom io import StringIO\nimport json\n \nwith open(\"default-credit-card.ipynb\", 'w') as f:\n    f.write(r\"\"\"${nbJson}\"\"\")\n\njvn_update = StringIO()\njvn_update_err = StringIO()\nwith redirect_stdout(jvn_update), redirect_stderr(jvn_update_err):\n    from jovian import commit\n\njvn_f_out = StringIO()\njvn_f_err = StringIO()\nwith redirect_stdout(jvn_f_out), redirect_stderr(jvn_f_err):\n    jvn_msg = jovian.commit(message=None, files=[], outputs=[], environment=None, privacy='auto', filename='default-credit-card.ipynb', project='default-credit-card', new_project=None)\n\nprint(json.dumps({'msg': jvn_msg, 'err': jvn_f_err.getvalue(), 'update': jvn_update.getvalue()}))\n        `;\n\n        console.log(\"Invoking jovian.commit\")\n        // console.log(pythonCode)\n\n        Jupyter.notebook.kernel.execute(pythonCode, { iopub: { output: jvnLog }});\n    });"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Conclusion and Future Steps:\n\nUsing the above factors of age, , we were able to achieve an accuracy of 78% which isn't good. With more data, this will improve. For next steps, try to see if more advanced neural network models can be applicable here. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}